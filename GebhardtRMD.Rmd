---
title: "CaseStudy2"
author: "Mike Gebhardt"
date: "12/2/2021"
output: html_document
---

library(psych)
library(class)
library(tidyverse)
library(ggplot)
library(caret)
library(randomForest)

#Several values are providing no value to the analysis: ID and EmployeeNumber are merely unique identifiers with no statistical impact; StandardHours is always equal to 80; EmployeeCount is always 1; Over18 is always equal to "Y" - these were all removed from the data and a clean dataframe was created 

View(CaseStudy2)

dim(CaseStudy2$StandardHours != 80) #No value exists other than 80

dim(CaseStudy2$EmployeeCount != 1) #No value exists other than 1

dim(CaseStudy2$Over18 != "Y") #No value exists other than "Y"

CaseStudy2_clean.df <- CaseStudy2 %>% dplyr::select(Age,Attrition,BusinessTravel,DailyRate,Department,DistanceFromHome,Education,EducationField,EnvironmentSatisfaction,Gender,HourlyRate,JobInvolvement,JobLevel,JobRole,JobSatisfaction,MaritalStatus,MonthlyIncome,MonthlyRate,NumCompaniesWorked,OverTime,PercentSalaryHike,PerformanceRating,RelationshipSatisfaction,StockOptionLevel,TotalWorkingYears,TrainingTimesLastYear,WorkLifeBalance,YearsAtCompany,YearsInCurrentRole,YearsSinceLastPromotion,YearsWithCurrManager)

sumtable(CaseStudy2_clean.df) #Overall summary of the data set

#Looking at the summary data, the following observations can be made: HR Staffing total seems low, only 4% of overall staffing.  HR tends to deal with employee issues, can help prevent attrition.  JobSatisfaction mean is lower than PerformanceRating, seems as though high performing employees are not satisfied.  TrainingHours seem very low for an R&D focused employee base (Max = 6).  Training can lead to advancement, improvement in JobSatisfaction, etc

#Next, we'll look for any obvious correlation between the numerical variables in the data

corrplot(CaseStudy_numeric, type = "lower")

#Looking at this plot, the only variables with strong correlation are the TotalWorkingYears with Age, Job Level and Monthlky Income - but these are to be expected.  As someone works longer, they age and typically increase their Job Levels and Income.  Monthly Income is strongly correlated with Job Level, Performance Rating is correlated with Percent SalaryHike and YearsAtCompany is positively correlated with YearsInCurrentRole, YearsSinceLastPromotion and YearsWithCurrManager.  None of these are surpirsing or revealing Analysis, so we will continue on.

#Since the excercise is looking at both Attrition and Salary, let's take a closer look at the salary variables: HourlyRate, DailyRate, MonthlyRate, MonthlyIncome

IncomeData <- CaseStudy2_clean.df[,c('HourlyRate','DailyRate','MonthlyRate','MonthlyIncome')]

IncomeData

#Next, we'll look to see if any of these financial measures are correlated to each other.  In looking at the output, there is no strong correlation between any of these variables

cor(IncomeData)

                HourlyRate     DailyRate MonthlyRate MonthlyIncome
HourlyRate     1.000000000  4.849597e-02 -0.01603517  2.391151e-03
DailyRate      0.048495974  1.000000e+00 -0.02764077  8.790339e-05
MonthlyRate   -0.016035168 -2.764077e-02  1.00000000  6.459407e-02
MonthlyIncome  0.002391151  8.790339e-05  0.06459407  1.000000e+00

#Looking at a boxplot of the data set, it appears that all of the values are normally distributed except for MonthlyIncome.  This may indicate that the Hourly, Daily and Monthly Rate values are for exempt (non-salaried) employees.  The Monthly Income data appears right-skewed - as expected - with fewer individuals with higher salaries.

boxplot(IncomeData,
          xlab = 'Financial Measure',
          ylab = 'Dollar Amounts', 
          lex.order = TRUE)

#Looking at a scatterplot of all of these values together, there is no clear discernable pattern that emerges - there seems to be no direct correlation between any of these variables, which is strange.  One would expect that the hourly/daily/monthly values would be related - but they do not appear so.

pairs.panels(IncomeData)
      
#Now we will attempt to determine the top variables affecting Attrition.  First, we use the Random Forest method and come up with the following:

CaseStudy2_Clean_forest <- randomForest(Attrition ~., 
                                        data = CaseStudy2_clean.df, 
                                        importance = TRUE)

varImpPlot(CaseStudy2_Clean_forest)
                                        
#This shows the following factors as the most influential: OverTime, MonthlyIncome, StockOptionLevel, YearsAtCompany and TotalWorkingYears.

AttritionRF <- train(Attrition ~ .,
                data = AttritionKNNtrain,
                method = "rf",
                trControl = train.cv,
                importance = TRUE)

AttritionKNNtest$AttritionRFPredict <- predict(AttritionRF, newdata = AttritionKNNtest)

confusionMatrix(table(AttritionKNNtest$Attrition, AttritionKNNtest$AttritionRFPredict))

#Confusion Matrix and Statistics

     
#       No Yes
#  No  182   0
#  Yes  33   2
                                          
#               Accuracy : 0.8479          
#                 95% CI : (0.7931, 0.8929)
#    No Information Rate : 0.9908          
#    P-Value [Acc > NIR] : 1               
                                          
#                  Kappa : 0.0923          
                                          
# Mcnemar's Test P-Value : 2.54e-08        
#                                          
#            Sensitivity : 0.84651         
#            Specificity : 1.00000         
#         Pos Pred Value : 1.00000         
#         Neg Pred Value : 0.05714         
#             Prevalence : 0.99078         
#         Detection Rate : 0.83871         
#   Detection Prevalence : 0.83871         
#      Balanced Accuracy : 0.92326         
                                          
#       'Positive' Class : No 

#Next, we ran a 75/25 KNN algorithm to compare to the Random Forest results 

AttritionKNN <- createDataPartition(CaseStudy2_clean.df$Attrition, p = 0.75, list = F)

AttritionKNNtrain <- CaseStudy2_clean.df [AttritionKNN,]

AttritionKNNtest <- CaseStudy2_clean.df [-AttritionKNN,]

train.knn <- trainControl(
              method = "repeatedcv",
              number = 5,
              repeats = 25,
              summaryFunction = twoClassSummary,
              classProbs = TRUE)

AttritionKNN2 <- train(
                  Attrition ~ .,
                  data = AttritionKNNtrain,
                  metric = "Spec",
                  method = "knn",
                  preProcess = c("center","scale"),
                  trControl = train.knn,
                  tuneLength = 6)
                  
AttritionKNNtest$AttritionKNNPredict <- predict(AttritionKNN2, newdata = AttritionKNNtest)

confusionMatrix(table(AttritionKNNtest$Attrition, AttritionKNNtest$AttritionKNNPredict))

#Confusion Matrix and Statistics

#      No    Yes
#  No  180   2
#  Yes 29    6
                                         
#               Accuracy : 0.8618          
#                 95% CI : (0.8086, 0.9047)
#    No Information Rate : 0.9585          
#    P-Value [Acc > NIR] : 1               
                                          
#                  Kappa : 0.27           
                                          
# Mcnemar's Test P-Value : 5.01e-06     
                                          
#            Sensitivity : 0.8654          
#            Specificity : 0.7778          
#         Pos Pred Value : 0.9890          
#         Neg Pred Value : 0.2000          
#             Prevalence : 0.9585          
#         Detection Rate : 0.8295          
#   Detection Prevalence : 0.8387          
#      Balanced Accuracy : 0.8216          
                                          
#       'Positive' Class : No 

#Drilling into some detail on specific factors, we've highlighted some of the top factors that are affecting Attrition:
 
ggplot(CaseStudy2_clean.df, aes(x= OverTime,  group=Attrition)) + 
     geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
     geom_text(aes( label = scales::percent(..prop..),
                    y= ..prop.. ), stat= "count", vjust = -.5) +
     labs(y = "Percent", fill="Attrition") +
     facet_grid(~Attrition) +
     scale_y_continuous(labels = scales::percent)
 
ggplot(CaseStudy2_clean.df, aes(x= MonthlyIncome,  group=Attrition)) + 
     geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
     geom_text(aes( label = scales::percent(..prop..),
                    y= ..prop.. ), stat= "count", vjust = -.5) +
     labs(y = "Percent", fill="Attrition") +
     facet_grid(~Attrition) +
     scale_y_continuous(labels = scales::percent)
 
ggplot(CaseStudy2_clean.df, aes(x= StockOptionLevel,  group=Attrition)) + 
     geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
     geom_text(aes( label = scales::percent(..prop..),
                    y= ..prop.. ), stat= "count", vjust = -.5) +
     labs(y = "Percent", fill="Attrition") +
     facet_grid(~Attrition) +
     scale_y_continuous(labels = scales::percent)
 
ggplot(CaseStudy2_clean.df, aes(x= YearsAtCompany,  group=Attrition)) + 
     geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
     geom_text(aes( label = scales::percent(..prop..),
                    y= ..prop.. ), stat= "count", vjust = -.5) +
     labs(y = "Percent", fill="Attrition") +
     facet_grid(~Attrition) +
     scale_y_continuous(labels = scales::percent)
 
ggplot(CaseStudy2_clean.df, aes(x= MaritalStatus,  group=Attrition)) + 
     geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
     geom_text(aes( label = scales::percent(..prop..),
                    y= ..prop.. ), stat= "count", vjust = -.5) +
     labs(y = "Percent", fill="Attrition") +
     facet_grid(~Attrition) +
     scale_y_continuous(labels = scales::percent)
 
ggplot(CaseStudy2_clean.df, aes(x= TotalWorkingYears,  group=Attrition)) + 
     geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
     geom_text(aes( label = scales::percent(..prop..),
                    y= ..prop.. ), stat= "count", vjust = -.5) +
     labs(y = "Percent", fill="Attrition") +
     facet_grid(~Attrition) +
     scale_y_continuous(labels = scales::percent)
 
ggplot(CaseStudy2_clean.df, aes(x= JobInvolvement,  group=Attrition)) + 
     geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
     geom_text(aes( label = scales::percent(..prop..),
                    y= ..prop.. ), stat= "count", vjust = -.5) +
     labs(y = "Percent", fill="Attrition") +
     facet_grid(~Attrition) +
     scale_y_continuous(labels = scales::percent)

#For MonthlyIncome predictors, we used a linear regression model to determine the variables with the greatest influence

CaseStudy2_clean.df_lm <- lm(MonthlyIncome ~ ., data =  CaseStudy2_clean.df)

summary(CaseStudy2_clean.df_lm)

#Residuals:
#    Min      1Q  Median      3Q     Max 
#-3680.7  -660.4     7.4   625.3  4114.4 

#Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
#(Intercept)                       6.322e+01  7.725e+02   0.082  0.93479    
#Age                              -1.430e+00  5.659e+00  -0.253  0.80049    
#AttritionYes                      8.245e+01  1.156e+02   0.714  0.47573    
#BusinessTravelTravel_Frequently   1.956e+02  1.422e+02   1.375  0.16950    
#BusinessTravelTravel_Rarely       3.777e+02  1.202e+02   3.143  0.00173 ** 
#DailyRate                         1.449e-01  9.138e-02   1.586  0.11312    
#DepartmentResearch & Development  1.205e+02  4.774e+02   0.252  0.80083    
#DepartmentSales                  -4.485e+02  4.885e+02  -0.918  0.35883    
#DistanceFromHome                 -6.712e+00  4.577e+00  -1.466  0.14290    
#Education                        -3.377e+01  3.718e+01  -0.908  0.36398    
#EducationFieldLife Sciences       1.294e+02  3.695e+02   0.350  0.72633    
#EducationFieldMarketing           1.039e+02  3.915e+02   0.266  0.79067    
#EducationFieldMedical             1.976e+01  3.704e+02   0.053  0.95746    
#EducationFieldOther               7.569e+01  3.952e+02   0.192  0.84816    
#EducationFieldTechnical Degree    8.523e+01  3.848e+02   0.221  0.82476    
#EnvironmentSatisfaction          -4.545e+00  3.369e+01  -0.135  0.89271    
#GenderMale                        1.112e+02  7.454e+01   1.492  0.13606    
#HourlyRate                       -3.812e-01  1.827e+00  -0.209  0.83478    
#JobInvolvement                    1.807e+01  5.328e+01   0.339  0.73450    
#JobLevel                          2.786e+03  8.353e+01  33.356  < 2e-16 ***
#JobRoleHuman Resources           -2.054e+02  5.156e+02  -0.398  0.69052    
#JobRoleLaboratory Technician     -6.021e+02  1.715e+02  -3.512  0.00047 ***
#JobRoleManager                    4.280e+03  2.835e+02  15.099  < 2e-16 ***
#JobRoleManufacturing Director     1.742e+02  1.697e+02   1.027  0.30480    
#JobRoleResearch Director          4.056e+03  2.193e+02  18.489  < 2e-16 ***
#JobRoleResearch Scientist        -3.482e+02  1.704e+02  -2.043  0.04135 *  
#JobRoleSales Executive            5.179e+02  3.579e+02   1.447  0.14830    
#JobRoleSales Representative       8.120e+01  3.923e+02   0.207  0.83605    
#JobSatisfaction                   2.736e+01  3.339e+01   0.819  0.41288    
#MaritalStatusMarried              6.666e+01  1.001e+02   0.666  0.50555    
#MaritalStatusSingle               1.520e+01  1.355e+02   0.112  0.91072    
#MonthlyRate                      -9.243e-03  5.148e-03  -1.796  0.07294 .  
#NumCompaniesWorked                4.915e+00  1.693e+01   0.290  0.77164    
#OverTimeYes                      -1.536e+01  8.446e+01  -0.182  0.85577    
#PercentSalaryHike                 2.520e+01  1.583e+01   1.592  0.11187    
#PerformanceRating                -3.247e+02  1.617e+02  -2.008  0.04494 *  
#RelationshipSatisfaction          1.621e+01  3.331e+01   0.487  0.62665    
#StockOptionLevel                  4.062e+00  5.695e+01   0.071  0.94316    
#TotalWorkingYears                 5.124e+01  1.099e+01   4.661 3.66e-06 ***
#TrainingTimesLastYear             2.375e+01  2.917e+01   0.814  0.41574    
#WorkLifeBalance                  -3.616e+01  5.169e+01  -0.700  0.48441    
#YearsAtCompany                   -4.709e+00  1.363e+01  -0.345  0.72990    
#YearsInCurrentRole                5.629e+00  1.703e+01   0.330  0.74111    
#YearsSinceLastPromotion           3.048e+01  1.534e+01   1.987  0.04723 *  
#YearsWithCurrManager             -2.576e+01  1.670e+01  -1.542  0.12341    
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 1057 on 825 degrees of freedom
#Multiple R-squared:  0.9498,	Adjusted R-squared:  0.9483 
#F-statistic: 354.9 on 44 and 825 DF,  p-value: < 2.2e-16

#Then we decided to utilize the Stepwise Regression feature to ensure that we have selected the proper variables:

trainControl_sw <- trainControl(method = "cv", number = 3)

MonthlyIncomeStepwise <- train(MonthlyIncome~.,data = CaseStudy2_clean.df, method = "lmStepAIC", trControl = trainControl_sw)

summary(MonthlyIncomeStepwise)

#Residuals:
#    Min      1Q  Median      3Q     Max 
#-3784.9  -666.9   -12.5   622.0  4126.2 

#Coefficients:
#                                  Estimate Std. Error t value Pr(>|t|)    
#(Intercept)                      3.284e+02  4.310e+02   0.762  0.44634    
#BusinessTravelTravel_Frequently  2.294e+02  1.380e+02   1.663  0.09670 .  
#BusinessTravelTravel_Rarely      4.042e+02  1.167e+02   3.463  0.00056 ***
#DailyRate                        1.487e-01  8.936e-02   1.664  0.09651 .  
#DepartmentSales                 -5.312e+02  1.623e+02  -3.272  0.00111 ** 
#DistanceFromHome                -6.646e+00  4.397e+00  -1.511  0.13107    
#GenderMale                       1.093e+02  7.303e+01   1.497  0.13480    
#JobLevel                         2.788e+03  7.989e+01  34.900  < 2e-16 ***
#JobRoleHuman Resources`        -4.508e+02  2.294e+02  -1.965  0.04968 *  
#JobRoleLaboratory Technician`  -6.833e+02  1.378e+02  -4.957 8.64e-07 ***
#JobRoleManager                   4.150e+03  2.266e+02  18.312  < 2e-16 ***
#JobRoleResearch Director`       3.947e+03  1.944e+02  20.303  < 2e-16 ***
#JobRoleResearch Scientist`     -4.403e+02  1.379e+02  -3.192  0.00147 ** 
#JobRoleSales Executive`         4.008e+02  1.668e+02   2.403  0.01646 *  
#MonthlyRate                     -9.190e-03  5.031e-03  -1.827  0.06810 .  
#PercentSalaryHike                2.395e+01  1.552e+01   1.544  0.12308    
#PerformanceRating               -3.088e+02  1.588e+02  -1.945  0.05214 .  
#TotalWorkingYears                4.824e+01  8.427e+00   5.725 1.44e-08 ***
#YearsSinceLastPromotion          2.864e+01  1.364e+01   2.099  0.03612 *  
#YearsWithCurrManager            -2.648e+01  1.230e+01  -2.153  0.03156 *  
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 1046 on 850 degrees of freedom
#Multiple R-squared:  0.9494,	Adjusted R-squared:  0.9483 
#F-statistic: 839.5 on 19 and 850 DF,  p-value: < 2.2e-16

#Running these two regression models, we can find the five variables with the strongest linear relationship to MonthlyIncome are JobLevel, JobRoleManager, JobRoleResearchDirector, TotalWorkingYears, JobRoleLaboratoryTechnician and BusinessTravelTravel_Rarely

#Here is the code for predicting the Monthly Income

MonthlyIncomeLM <- createDataPartition(CaseStudy2_clean.df$MonthlyIncome, p = 0.75, list = F)

MonthlyIncomeLMtrain <- CaseStudy2_clean.df [MonthlyIncomeLM,]

MonthlyIncomeLMNtest <- CaseStudy2_clean.df [-MonthlyIncomeLM,]

CaseStudy2_clean.df$MonthlyIncomeLM <- predict(CaseStudy2_clean.df_lm, newdata = CaseStudy2_clean.df)

MonthlyIncomePrediction$MonthlyIncomeLM <- predict(CaseStudy2_clean.df_lm, newdata = MonthlyIncomePrediction)

view(MonthlyIncomePrediction)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
